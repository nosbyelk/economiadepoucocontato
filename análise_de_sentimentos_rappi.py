# -*- coding: utf-8 -*-
"""Análise de sentimentos Rappi

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SfeQsYI5KsrhSBFIMTyJjd8lmAiqcCbu

# **Análise de sentimentos – Rappi**
Pesquisa de Iniciação Científica vinculada ao curso de Economia da UFRPE.
"""

from google.colab import drive
drive.mount('/content/drive')

"""## **Análise de Sentimentos usando Machine Learning**

* Criando modelos para análise de sentimentos de tweets
"""

from nltk import word_tokenize
import nltk
import re
import pandas as pd
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn import svm
from sklearn import metrics
from sklearn.model_selection import cross_val_predict
import numpy as np
import pandas as pd 
import nltk
import os
import pandas
from nltk.corpus import stopwords
from wordcloud import WordCloud 
from matplotlib import pyplot as plt
import nltk
nltk.download('stopwords')

"""**Ler arquivo de dados e conta a quantidade de linhas**"""

df = pd.read_csv('Rappi.csv', encoding='latin-1')

df.head()

"""**Conta a quantidade de linhas de tweets neutros, positivos e negativos**"""

df.tuites.value_counts()

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
df.tuites.value_counts().plot(kind='bar')

df.count()

df.drop_duplicates(['tuites'], inplace=True)

df.tuites.count()

df.describe()

df['length'] = df['tuites'].apply(len)
df.head()

df.length.describe()

df[df['length'] == 306]['tuites'].iloc[0]

text = " ".join(review for review in df.tuites.astype(str))

print ("There are {} words in the combination of all cells in column tuites.".format(len(text)))

stopwords = set(stopwords.words('portuguese'))

stopwords.update(["de", "a", "o", "que", "e", "do", "da", "em", "um", "para", "é", "com", "não", "uma", "os", "no", "se", "na", "por", "mais", "as", "dos", "como", "mas", "foi", "ao", "ele", "das", "tem", "à", "seu", "sua", "ou", "ser", "quando", "muito", "há", "nos", "já", "está", "eu", "também", "só", "pelo", "pela", "até", "isso", "ela", "entre", "era", "depois", "sem", "mesmo", "aos", "ter", "seus", "quem", "nas", "me", "esse", "eles", "estão", "você", "tinha", "foram", "essa", "num", "nem", "suas", "meu", "às", "minha", "têm", "numa", "pelos", "elas", "havia", "seja", "qual", "será", "nós", "tenho", "lhe", "deles", "essas", "esses", "pelas", "este", "fosse", "dele", "tu", "te", "vocês", "vos", "lhes", "meus", "minhas", "teu", "tua", "teus", "tuas", "nosso", "nossa", "nossos", "nossas", "dela", "delas", "esta", "estes", "estas", "aquele", "aquela", "aqueles", "aquelas", "isto", "aquilo", "estou", "está", "estamos", "estão", "estive", "esteve", "estivemos", "estiveram", "estava", "estávamos", "estavam", "estivera", "estivéramos", "esteja", "estejamos", "estejam", "estivesse", "estivéssemos", "estivessem", "estiver", "estivermos", "estiverem", "hei", "há", "havemos", "hão", "houve", "houvemos", "houveram", "houvera", "houvéramos", "haja", "hajamos", "hajam", "houvesse", "houvéssemos", "houvessem", "houver", "houvermos", "houverem", "houverei", "houverá", "houveremos", "houverão", "houveria", "houveríamos", "houveriam", "sou", "somos", "são", "era", "éramos", "eram", "fui", "foi", "fomos", "foram", "fora", "fôramos", "seja", "sejamos", "sejam", "fosse", "fôssemos", "fossem", "for", "formos", "forem", "serei", "será", "seremos", "serão", "seria", "seríamos", "seriam", "tenho", "tem", "temos", "tém", "tinha", "tínhamos", "tinham", "tive", "teve", "tivemos", "tiveram", "tivera", "tivéramos", "tenha", "tenhamos", "tenham", "tivesse", "tivéssemos", "tivessem", "tiver", "tivermos", "tiverem", "terei", "terá", "teremos", "terão", "teria", "teríamos", "teriam"
])

wordcloud = WordCloud(background_color="white", width=800, height=400).generate(text)
plt.axis("off")
plt.figure( figsize=(40,20))
plt.tight_layout(pad=0)
plt.imshow(wordcloud, interpolation='bilinear')
plt.show()